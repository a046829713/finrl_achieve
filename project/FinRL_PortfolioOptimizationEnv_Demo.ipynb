{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xt6fIDownZs"
   },
   "source": [
    "# A guide Portfolio Optimization Environment\n",
    "\n",
    "This notebook aims to provide an example of using PortfolioOptimizationEnv (or POE) to train a reinforcement learning model that learns to solve the portfolio optimization problem.\n",
    "\n",
    "In this document, we will reproduce a famous architecture called EIIE (ensemble of identical independent evaluators), introduced in the following paper:\n",
    "\n",
    "- Zhengyao Jiang, Dixing Xu, & Jinjun Liang. (2017). A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem. https://doi.org/10.48550/arXiv.1706.10059.\n",
    "\n",
    "It's advisable to read it to understand the algorithm implemented in this notebook.\n",
    "\n",
    "### Note\n",
    "If you're using this environment, consider citing the following paper (in adittion to FinRL references):\n",
    "\n",
    "- Caio Costa, & Anna Costa (2023). POE: A General Portfolio Optimization Environment for FinRL. In *Anais do II Brazilian Workshop on Artificial Intelligence in Finance* (pp. 132–143). SBC. https://doi.org/10.5753/bwaif.2023.231144.\n",
    "\n",
    "```\n",
    "@inproceedings{bwaif,\n",
    " author = {Caio Costa and Anna Costa},\n",
    " title = {POE: A General Portfolio Optimization Environment for FinRL},\n",
    " booktitle = {Anais do II Brazilian Workshop on Artificial Intelligence in Finance},\n",
    " location = {João Pessoa/PB},\n",
    " year = {2023},\n",
    " keywords = {},\n",
    " issn = {0000-0000},\n",
    " pages = {132--143},\n",
    " publisher = {SBC},\n",
    " address = {Porto Alegre, RS, Brasil},\n",
    " doi = {10.5753/bwaif.2023.231144},\n",
    " url = {https://sol.sbc.org.br/index.php/bwaif/article/view/24959}\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0L7FZeWMUHp"
   },
   "source": [
    "## Installation and imports\n",
    "\n",
    "To run this notebook in google colab, uncomment the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGHfTt1HMVQw",
    "outputId": "e5226807-a740-4f22-a279-f466886518ba"
   },
   "outputs": [],
   "source": [
    "## install finrl library\n",
    "# !sudo apt install swig\n",
    "# !pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-GLganWiMYZ1",
    "outputId": "b3a7f99c-55dd-4274-c1ce-ab3a8111929a"
   },
   "outputs": [],
   "source": [
    "## We also need to install quantstats, because the environment uses it to plot graphs\n",
    "# !pip install quantstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz8DLleGz_TF"
   },
   "source": [
    "#### Import the necessary code libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY2yhvpASEyo"
   },
   "source": [
    "## Fetch data\n",
    "\n",
    "In his paper, *Jiang et al* creates a portfolio composed by the top-11 cryptocurrencies based on 30-days volume. Since it's not specified when this classification was done, it's difficult to reproduce, so we will use a similar approach in the Brazillian stock market:\n",
    "\n",
    "- We select top-10 stocks from Brazillian stock market;\n",
    "- For simplicity, we disconsider stocks that have missing data for a days in period 2011-01-01 to 2019-12-31 (9 years);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VoUmKc-Rzyv"
   },
   "source": [
    "## Portfolio Optimization Environment\n",
    "\n",
    "Since POE was not merged to FinRL yet, we add its code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtrVGFgnWAB7"
   },
   "source": [
    "## Define Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SmWkjyfs7kc"
   },
   "source": [
    "#### Create the gradient policy\n",
    "\n",
    "The gradient policy below is identical to the EIIE architecture from *Jiang et al* paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bvQOW-hGWo1"
   },
   "source": [
    "#### Portfolio Vector Memory\n",
    "\n",
    "The portfolio vector memory is an object that saves all the portfolio vectors generated by the policy. It's useful because the algorithm can get the last action performed, an information necessary to do forward propagation. Read *Jiang et al* article for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpA1v31eIBq0"
   },
   "source": [
    "#### ReplayBuffer and RLDataset\n",
    "\n",
    "The replay buffer implemented in this work is slightly different from the one in famous algorithms. Usually, experiences are constantly added to the replay buffer and when it's completely filled, older experiences are overwritten by new ones (deque behavior). A reinforcement learning algorithm can constantly sample experiences from the buffer to update their neural networks and, as the time passes, older experiences will be disconsidered due to the deque behavior.\n",
    "\n",
    "In this replay buffer, however, the deque behavior is still present, but when an algorithm sample a batch of experiences, all the experiences in the replay buffer are returned and it is cleared. This behavior is necessary given the policy gradient algorithm introduced by *Jiang et al*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpkzhBiHIXus"
   },
   "source": [
    "#### Create Polyak average function\n",
    "\n",
    "The Polyak average function allows us to have a target function that is incrementally updated. It's useful to avoid oscillations in the final policy performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKFPro4q657H"
   },
   "source": [
    "### Create PG class\n",
    "\n",
    "This class implements the Policy Gradient algorithm used in *Jiang et al* paper. This algorithm is inspired by DDPG (deep deterministic policy gradient), but there are a couple of differences: \n",
    "- DDPG is an actor-critic algorithm, so it has an actor and a critic neural network. The algorithm below, however, doesn't have a critic neural network and uses the portfolio value as value function: the policy will be updated to maximize the portfolio value.\n",
    "- DDPG usually makes use of a noise parameter in the action during training to create an exploratory behavior. PG algorithm, on the other hand, has a full-exploit approach.\n",
    "- DDPG randomly samples experiences from its replay buffer. The implemented policy gradient, however, samples a sequential batch of experiences in time, to make it possible to calculate the variation of the portfolio value in the batch and use it as value function.\n",
    "\n",
    "The algorithm can be described as follows:\n",
    "1. Initializes policy network, target policy network (if used) and replay buffer;\n",
    "2. For each episode, do the following:\n",
    "    1. For each period of `batch_size` timesteps, do the following:\n",
    "        1. For each timestep, define an action to be performed, simulate the timestep and save the experiences in the replay buffer.\n",
    "        2. After `batch_size` timesteps are simulated, sample the replay buffer.\n",
    "        3. Update target policy network (if used).\n",
    "        4. Calculate the value function: $V = \\sum\\limits_{t=1}^{batch\\_size} ln(\\mu_{t}(W_{t} \\cdot P_{t}))$, where $W_{t}$ is the action performed at timestep t, $P_{t}$ is the price variation vector at timestep t and $\\mu_{t}$ is the transaction remainder factor at timestep t. Check *Jiang et al* paper for more details.\n",
    "        5. Perform gradient ascent in the policy network.\n",
    "    2. If, in the and of episode, there is sequence of remaining experiences in the replay buffer, perform steps \"a\" to \"e\" with the remaining experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM829994GWo3"
   },
   "source": [
    "### Train Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JE7X3qEeXOr4"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FRK9A98XVck"
   },
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pstJ-uY1_7VY"
   },
   "source": [
    "### Define test periods\n",
    "In this work, we are going to use three annual test periods: the year of 2020, 2021 and 2022. To get data from Yahoo Finance, we do just like in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFYB9iGwAPSh"
   },
   "source": [
    "### Instantiate different environments\n",
    "\n",
    "Since we have three different periods of time, we need three different environments instantiated to simulate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4RuS2pRAa4H"
   },
   "source": [
    "### Test EIIE architecture\n",
    "Now, we can test the EIIE architecture in the three different test periods. It's important no note three things:\n",
    "- In this code, we load the saved policy even though it's not necessary just to show how to save and load your model;\n",
    "- It's important to reset the environment before an episode and to create a new PVM (portfolio vector memory) for each case\n",
    "- The neural network is expecting a batch of data, so it's necessary to create an additional dimension to the input data if it's a single item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZc5PpbaBU-J"
   },
   "source": [
    "### Test Uniform Buy and Hold\n",
    "For comparison, we will also test the performance of a uniform buy and hold strategy. In this strategy, the portfolio has no remaining cash and the same percentage of money is allocated in each asset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBMM7hAHC6rq"
   },
   "source": [
    "### Plot graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1f84695a1caf4c80b29eb5eea90bb29a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "317393fb13c0449abfff29a4949553a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f84695a1caf4c80b29eb5eea90bb29a",
      "placeholder": "​",
      "style": "IPY_MODEL_a7a6884bfdb642b9b342f7cda49d7d67",
      "value": " 10/250 [05:53&lt;2:10:07, 32.53s/it]"
     }
    },
    "4b2aa7128c5d4d15bb794eb76faccd6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a1187acb99d44c68e27cd5aad879ff1",
      "max": 250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6a5c9dbaddc441d390d4827c170cbe9c",
      "value": 10
     }
    },
    "6a1187acb99d44c68e27cd5aad879ff1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a5c9dbaddc441d390d4827c170cbe9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "750b2ea28d2a439db3fc5034927dbce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c172e120fc5e4f9ab13bf8599d868b5f",
       "IPY_MODEL_4b2aa7128c5d4d15bb794eb76faccd6a",
       "IPY_MODEL_317393fb13c0449abfff29a4949553a0"
      ],
      "layout": "IPY_MODEL_8cb75a82e5374c51b1f47a6e15783177"
     }
    },
    "8cb75a82e5374c51b1f47a6e15783177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cb3d937be5d4f7cac192b392218ef37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7a6884bfdb642b9b342f7cda49d7d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b27b9cc333ac44a5bb2cec60d02f16c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c172e120fc5e4f9ab13bf8599d868b5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cb3d937be5d4f7cac192b392218ef37",
      "placeholder": "​",
      "style": "IPY_MODEL_b27b9cc333ac44a5bb2cec60d02f16c0",
      "value": "  4%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
